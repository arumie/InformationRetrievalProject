{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Project\n",
    "\n",
    "### In order to evaluate the Nordlys toolkit, we want to answer to the following questions:\n",
    "- How  are  Nordlys  toolkit  performances,  considering  the  different  types  of  questions  (SemSearchES,INEX-LD, QALD2, ListSearch)?\n",
    "- How are Nordlys performances compared to the Google search engines?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we load the list of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('query_list.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "raw_queries = text.split(\"\\n\")\n",
    "raw_queries[0].split(\"\\t\")\n",
    "\n",
    "list_queries=[]\n",
    "for i in list_queries:\n",
    "    list_queries.append(i.split(\"\\t\")[1])\n",
    "    \n",
    "list_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to calculate MAP and Normalized DCG we need to know how many relevant results exist for each query. Here we make a list of size 3 for each query. The number in index i in the list is the number of rated documents with score i for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "f2 = codecs.open(\"query_relevance.txt\", encoding=\"utf-8\")\n",
    "text = f2.read()\n",
    "\n",
    "\n",
    "relevance_lines = text.split(\"\\n\")\n",
    "\n",
    "query_counts = {}\n",
    "current_query = text.split(\"\\n\")[0].split(\"\\t\")[0]\n",
    "temp_count_list = [0,0,0]\n",
    "\n",
    "\n",
    "counter = 0\n",
    "while (counter < len(relevance_lines)):\n",
    "    query_name = relevance_lines[counter].split(\"\\t\")[0]\n",
    "    relevance = relevance_lines[counter].split(\"\\t\")[3]\n",
    "    if query_name != current_query:\n",
    "        query_counts[current_query] = temp_count_list\n",
    "        current_query = query_name\n",
    "        temp_count_list = [0,0,0]\n",
    "        \n",
    "    temp_count_list[int(relevance)] += 1\n",
    "    counter += 1\n",
    "    if counter == len(relevance_lines):\n",
    "        query_counts[current_query] = temp_count_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nordlys Entity Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Mean Average Precision (MAP) measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we will calculate the MAP of a list of query results. The result of a single query consist of the name of the query, and a list of tuples containing the retrieved document and the relevancy of that document. These tuples are in the same order as they were returned from the retrieval system.\n",
    "\n",
    "Since MAP only works on binary relevancy levels, we have decided that both the level 1 and 2 are relevant while level 0 is not relevant.\n",
    "\n",
    "P(q,k) calculates the precision of a query q at k retrieved documents but only on steps wher the new retrieved document is considered to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_queries = {\"INEX_LD-20120111\":[(\"d1\",1),(\"d2\",0),(\"d3\",0),(\"d4\",2),(\"d5\",1)],\"INEX_LD-20120112\":[(\"d11\",2),(\"d21\",1),(\"d33\",0),(\"d4\",2),(\"d5\",1)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Returns true if the document is relevant (values 1 and 2)\n",
    "def rel(q,k,input_queries):\n",
    "    return int(input_queries[q][k][1]) > 0\n",
    "\n",
    "#Returns the precision at k for query q\n",
    "def P(q,k,input_queries):\n",
    "    k_retrieved = input_queries[q][0:(k)]\n",
    "    relevant_retrieved = (x for x in k_retrieved if int(x[1]) > 0)    \n",
    "    return len(list(relevant_retrieved))/(len(k_retrieved)*1.0)\n",
    "\n",
    "#Takes he average of the precisions of query q for k = max_k\n",
    "def AveP(q,input_queries,max_k):\n",
    "    res = 0\n",
    "    for k in range(0,max_k):\n",
    "        res += np.dot(P(q,k+1,input_queries),rel(q,k+1,input_queries))\n",
    "    number_of_relevant = np.minimum(max_k,(query_counts[q][1] +  query_counts[q][2]))\n",
    "    if (number_of_relevant == 0):\n",
    "        return 0\n",
    "    return res/(number_of_relevant*1.0)\n",
    "\n",
    "def MAP(input_queries,k):    \n",
    "    res = 0\n",
    "    for q in input_queries:\n",
    "        if len(input_queries[q])> k:\n",
    "            addition = AveP(q,input_queries,k)\n",
    "            res += addition    \n",
    "    return res/len(input_queries)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Discounted Cumulative Gain (DCG) measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discounted cumulative gain sums the knowledge gain of each retrieved document divided by log2 of the position. This means that a a very important document (rank 2) at position 3 will give a higher score than a very important document at position 10.\n",
    "\n",
    "For each query we calculate DCG@k meaning that only the first k query results are considered in the calculation.\n",
    "For the normalization we also calculate IDCG, which is the ideal DCG for a perfect ranking. This is done based on the list how many relevant documents of each rank exists for each query.\n",
    "\n",
    "Since we have more than one query for each search engine, we return the average NDCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Calculate Discounted Cumulative Gain\n",
    "def DCG(query_results,k):\n",
    "    dcg = float(query_results[0][1])\n",
    "    for i in range(1,k):\n",
    "        dcg += float(query_results[i][1])/float(np.log2(i+1))\n",
    "    return dcg\n",
    "\n",
    "#The score for a per fect ranking\n",
    "def IDCG(q,k):\n",
    "    #savek in j for later\n",
    "    j = k\n",
    "    relevant_for_query = query_counts[q]\n",
    "    gains = []\n",
    "    #Add all gains of 2 and subtract that number from k\n",
    "    for i in range(max(k,relevant_for_query[2])):\n",
    "        gains.append([\"Dummy\",2])\n",
    "    k = k-relevant_for_query[2]\n",
    "    #Add all gains of 1 and subtract that number from k\n",
    "    for i in range(max(k,relevant_for_query[1])):\n",
    "        gains.append([\"Dummy\",1])\n",
    "    k = k-relevant_for_query[1]\n",
    "    #Fill the rest of the list with gain of 0 to avoid indexing problems\n",
    "    for i in range(k):\n",
    "        gains.append([\"Dummy\",0])        \n",
    "    \n",
    "    idcg = DCG(gains,j)    \n",
    "    #print(idcg)\n",
    "    return idcg\n",
    "    \n",
    "\n",
    "#Calculates the average NDCG for the first k documents\n",
    "def AvgNDCG(input_queries,k):\n",
    "    sum_ndcg = 0\n",
    "    for q in input_queries:\n",
    "        if len(input_queries[q]) >= 20:\n",
    "            addition = (DCG(input_queries[q],k)/IDCG(q,k))\n",
    "            sum_ndcg += addition\n",
    "    return sum_ndcg/len(input_queries)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for Nordlys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2012253154880168\n",
      "0.136799995873\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "nordlys_reader = codecs.open(\"nordlys_retrievals_jm.txt\", encoding=\"utf-8\")\n",
    "text = nordlys_reader.read()\n",
    "import json\n",
    "Nordlys_queries = json.loads(text)\n",
    "\n",
    "print(AvgNDCG(Nordlys_queries,10))\n",
    "\n",
    "print(MAP(Nordlys_queries,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
